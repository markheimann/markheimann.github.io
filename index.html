---
layout: default
title: Mark Heimann
---
<div class="blurb">
  <p>
    I am a PhD candidate in the computer science department at the University of Michigan, where I consider myself fortunate to be a member of the <a href="https://gemslab.github.io/">GEMS Lab</a> and advised by <a href="http://web.eecs.umich.edu/~dkoutra">Danai Koutra</a>. I am spending the summer of 2019 at the <a href="https://www.isi.edu/">Information Sciences Institute</a> in California working with <a href="http://www.emilio.ferrara.name/">Emilio Ferrara</a> on using node embeddings to analyze network dynamics in online communities, after spending Winter 2019 interning remotely with <a href="http://ryanrossi.com/">Ryan Rossi</a> at <a href="https://research.adobe.com/">Adobe Research</a> working on entity resolution.  In the summer of 2018 I was at <a href="https://www.ornl.gov/">Oak Ridge National Laboratory</a>, working with <a href="https://www.ornl.gov/staff-profile/ramakrishnan-ramki-kannan">Ramakrishnan Kannan</a> on nonlinear dimensionality reduction.  We collaborated with researchers at the <a href="https://www.ornl.gov/facility/cnms">Center for Nanophase Materials Sciences</a> to develop new algorithms for hyperspectral unmixing.
  </p>

<p>
    My current research focuses on representation learning in networks, where I am developing methods for node embedding that preserve the similarity between nodes with similar structural roles in a network or networks.  Such node embeddings are comparable even across entirely different networks, for example when performing multi-network tasks such as network alignment or classification.  I have broader interests in methods and applications for representation learning, matrix factorization, and nonlinear dimensionality reduction.  

</p> 

<!-- 
<h2>Research Projects</h2>
<ul>
<div class="blurb">

  <img src="assets/project_figs/REGAL.png" class = "project_figs" align = "right">
  <li><b>Multi-Network Representation Learning: </b> We propose REGAL, a framework for network alignment that leverages latent feature representations of nodes (also known as node embeddings) in multiple networks.  Most existing node embedding methods, despite their popularity for downstream graph mining tasks on a single graph, produce embeddings that are not comparable across multiple graphs.  Thus, as part of REGAL we develop a new method for node embedding, Cross-network Matrix Factorization (xNetMF) that a) preserves node similarities based on structural identity and attribute information (if available) that can be compared in multiple graphs, and b) omits the variance-inducing context sampling with random walks that many competing methods use.  Leveraging techniques from low-rank matrix approximation for embedding, and efficient data structure for embedding matching, allows REGAL to scale to extremely large networks.  
    <BR clear="left">
</div>
  	&nbsp;
  	&nbsp;
  	&nbsp;
  	&nbsp;
<BR clear="left">
<div class="blurb">
  <img src="assets/project_figs/HashAlign.png" class = "project_figs" align = "right"> 
  <li><b>Fast Network Alignment: </b> We develop HashAlign, a flexible framework for aligning graphs quickly by using locality-sensitive hashing to avoid comparing all possible combinations of nodes.  Instead, with high probability we only compare the most similar nodes based on feature vectors for which we propose sensible construction methods.  This framework is flexible, as it can be easily extended to graphs where node and/or edge attributes are known; if known, they can be incorporated into the nodes' feature vectors. 
  </div>
&nbsp;
&nbsp;
&nbsp;
&nbsp;
<BR clear="left">
<div class="blurb">
  <img src="assets/project_figs/FLOWR.png" class = "project_figs" align = "right">
  <li><b>Solving Large-Scale Linear Systems: </b> We develop FLOWR, a fast "flow"-based methods for solving network problems that can be expressed as linear systems, including Random Walk with Restart (RWR), in a distributed setting.  Such systems, we show, can be solved in a divide-and-conquer fashion by breaking them into subproblems (smaller clusters of the original network) such that the communication between subproblems (vertices adjacent to vertices in other clusters, or "flow") is minimized.  Furthermore, our method can leverage the benefit of overlapping clusters, which makes individual clusters larger, but minimizes the amount of communication across clusters. 
</div>
</ul>
<BR clear="left">

&nbsp;
&nbsp;
&nbsp;
&nbsp;
-->

<h2>Publications</h2>
<div class="blurb">
<ul>
	<li> Di Jin, <b>Mark Heimann</b>, Ryan Rossi, and Danai Koutra.  <a href="https://arxiv.org/pdf/1904.08572.pdf">node2bits: Compact Time- and Attribute-aware
Node Representations for User Stitching</a>. European Conference on Principles and Practice of Knowledge Discovery in Databases (PKDD), 2019.
	<li> Di Jin*, <b>Mark Heimann</b>*, Tara Safavi, Mengdi Wang, Wei Lee, Lindsay Snider, and Danai Koutra.  <a href="https://gemslab.github.io/papers/jin-2019-roles.pdf">Smart Roles: Inferring Professional Roles in Email Networks</a>. Conference on Knowledge Discovery and Data Mining (KDD), 2019.  
 	<li> <b>Mark Heimann</b>, Haoming Shen, Tara Safavi, and Danai Koutra.  <a href="papers/REGAL-CIKM18.pdf">REGAL: Representation Learning-based Graph Alignment</a>. International Conference on Information and Knowledge Management (CIKM), 2018.  [<a href="https://github.com/GemsLab/REGAL">code</a>]
	<li> <b>Mark Heimann</b>*, Wei Lee*, Shengjie Pan, Kuan-Yu Chen, and Danai Koutra.  <a href="papers/HashAlign-PAKDD18-full.pdf">HashAlign: Hash-Based Alignment of Multiple Graphs</a>.  Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD), 2018.
	<li> Yujun Yan, <b>Mark Heimann</b>, Di Jin, and Danai Koutra.  <a href="http://web.eecs.umich.edu/~dkoutra/papers/18_FlowR_SDM_CR.pdf">Fast Flow-based Random Walk with Restart in a Multi-query Setting</a>.  SIAM International Conference on Data Mining (SDM), 2018.
<li> <b>Mark Heimann</b> and Danai Koutra. <a href="http://www.mlgworkshop.org/2017/paper/MLG2017_paper_26.pdf">On Generalizing Neural Node Embedding Methods to Multi-Network Problems</a>. KDD Workshop on Mining and Learning with Graphs (MLG), 2017.
</ul>

<h5>*Equal contribution</h5>
</div>
